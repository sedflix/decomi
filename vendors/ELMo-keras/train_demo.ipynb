{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras.backend as K\n",
    "from elmo.lm_generator import LMDataGenerator, MTLLMDataGenerator\n",
    "from elmo.model_girnet import ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fastBPE\n",
    "# bpe = fastBPE.fastBPE(\"../twiter_scrapping/preprocess/fastBPE/codes\", \"../twiter_scrapping/data/vocab.en.es.40000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "- fasttext: sent_vector: unsup: [0.5040783036202435, 0.44986425566245447]\n",
    "- fasttext: sent_vector: sup: [0.5628058728541675, 0.5187983749157842]\n",
    "- fasttext: lstm: unsup [0.6182707995419401, 0.5768815131210775] \n",
    "- fasttext: lstm: sup [0.6705, 0.6624]\n",
    "- MultiBPEmb: lstm: unsup: 0.52\n",
    "- MultiBPEmb: lstm: sup: 0.64\n",
    "\n",
    "## Word Vocab\n",
    "\n",
    "### cm_p_test_1000.txt\n",
    "- vanilla :  46.75967671612614\n",
    "- mtl: 39.42567465448776\n",
    "- girnet: 165.677334\n",
    "\n",
    "###  cm_main_test_1000.txt\n",
    "- vanilla : 53.722(4), 73.619(32)\n",
    "- mtl:46.54(4), 58.723(32))\n",
    "- girnet: 22(4), 115(64)\n",
    "- qrnn: 341.52\n",
    "\n",
    "## BPE\n",
    "###  cm_main_test_1000.txt\n",
    "- vanilla_bpe: 51.959(1), 53.7539(4), 91.7316(64)\n",
    "- mlt_bpe: 46.614(4)\n",
    "- girnet_bpe: 18.187604(4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### VCS DATA\n",
    "- flair ~ 15\n",
    "- awd-lstm: 1105 \n",
    "- qrnn: 1048.25 (1621.41-16)\n",
    "- girnet_4_1: 363.432520 / no sampling: 214.172797/ 189.699757\n",
    "- mtl: 214.18284865336776, 166.37407541932322\n",
    "- vanilla_4_1: 420.294477 /no sampling: 136.28547085188885\n",
    "\n",
    "Conclusion: S4UBWORDS RULE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SET_DIR = '../twiter_scrapping/data/'\n",
    "# DATA_SET_DIR = '../../data/Dataset_VACS/Language Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#     'name': 'cm_mtl_4',\n",
    "#     'multi_processing': True,\n",
    "#     'n_threads': 10,\n",
    "#     'cuDNN': True if len(K.tensorflow_backend._get_available_gpus()) else False,\n",
    "#     'train_dataset': 'cm_p_train_small.txt',\n",
    "#     'valid_dataset': 'cm_p_test_1000.txt',\n",
    "#     'test_dataset': 'cm_test_main_1000.txt',\n",
    "#     'vocab': 'vocab',\n",
    "#     'vocab_size': 525133,\n",
    "#     'num_sampled': 8000,\n",
    "#     'charset_size': 262,\n",
    "#     'sentence_maxlen': 32,\n",
    "#     'token_maxlen': 50,\n",
    "#     'token_encoding': 'word',\n",
    "#     'epochs': 1,\n",
    "#     'patience': 2,\n",
    "#     'batch_size': 4,\n",
    "#     'clip_value': 1,\n",
    "#     'cell_clip': 5,\n",
    "#     'proj_clip': 5,\n",
    "#     'lr': 0.2,\n",
    "#     'shuffle': True,\n",
    "#     'n_lstm_layers': 1,\n",
    "#     'n_highway_layers': 1,\n",
    "#     'cnn_filters': [[1, 32],\n",
    "#                     [2, 32],\n",
    "#                     [3, 64],\n",
    "#                     [4, 128],\n",
    "#                     [5, 256],\n",
    "#                     [6, 512],\n",
    "#                     [7, 512]\n",
    "#                     ],\n",
    "#     'lstm_units_size': 400,\n",
    "#     'hidden_units_size': 200,\n",
    "#     'char_embedding_size': 16,\n",
    "#     'dropout_rate': 0.1,\n",
    "#     'word_dropout_rate': 0.05,\n",
    "#     'weight_tying': True,\n",
    "#     'unidirectional': True,\n",
    "#     'subwords': False,\n",
    "#      'use_multibpemd': False,\n",
    "# }\n",
    "\n",
    "# parameters = {\n",
    "#     'name': 'cm_mtl_bpe_4',\n",
    "#     'multi_processing': True,\n",
    "#     'n_threads': 10,\n",
    "#     'cuDNN': True if len(K.tensorflow_backend._get_available_gpus()) else False,\n",
    "#     'train_dataset': 'cm_p_train_small.txt.40000',\n",
    "#     'valid_dataset': 'cm_p_test_1000.txt.40000',\n",
    "#     'test_dataset': 'cm_test_main_1000.txt.40000',\n",
    "#     'vocab': 'vocab.en.es.40000.processed',\n",
    "#     'vocab_size': 54497,\n",
    "#     'num_sampled': 2000,\n",
    "#     'charset_size': 262,\n",
    "#     'sentence_maxlen': 32,\n",
    "#     'token_maxlen': 50,\n",
    "#     'token_encoding': 'word',\n",
    "#     'epochs': 1,\n",
    "#     'patience': 2,\n",
    "#     'batch_size': 4,\n",
    "#     'clip_value': 1,\n",
    "#     'cell_clip': 5,\n",
    "#     'proj_clip': 5,\n",
    "#     'lr': 0.2,\n",
    "#     'shuffle': True,\n",
    "#     'n_lstm_layers': 1,\n",
    "#     'n_highway_layers': 1,\n",
    "#     'cnn_filters': [[1, 32],\n",
    "#                     [2, 32],\n",
    "#                     [3, 64],\n",
    "#                     [4, 128],\n",
    "#                     [5, 256],\n",
    "#                     [6, 512],\n",
    "#                     [7, 512]\n",
    "#                     ],\n",
    "#     'lstm_units_size': 400,\n",
    "#     'hidden_units_size': 200,\n",
    "#     'char_embedding_size': 16,\n",
    "#     'dropout_rate': 0.1,\n",
    "#     'word_dropout_rate': 0.05,\n",
    "#     'weight_tying': True,\n",
    "#     'unidirectional': True,\n",
    "#     'subwords': False\n",
    "#     'use_multibpemd': False,\n",
    "# }\n",
    "\n",
    "\n",
    "# parameters = {\n",
    "#     'name': 'cm_girnet_vcs_data',\n",
    "#     'multi_processing': True,\n",
    "#     'n_threads': 10,\n",
    "#     'cuDNN': True if len(K.tensorflow_backend._get_available_gpus()) else False,\n",
    "#     'train_dataset': 'cm.txt',\n",
    "#     'valid_dataset': 'valid.txt',\n",
    "#     'test_dataset': 'test.txt',\n",
    "#     'vocab': 'fvocab',\n",
    "#     'vocab_size': 12688,\n",
    "#     'num_sampled': 12688,\n",
    "#     'charset_size': 262,\n",
    "#     'sentence_maxlen': 32,\n",
    "#     'token_maxlen': 50,\n",
    "#     'token_encoding': 'word',\n",
    "#     'epochs': 2,\n",
    "#     'patience': 4,\n",
    "#     'batch_size': 4,\n",
    "#     'clip_value': 1,\n",
    "#     'cell_clip': 5,\n",
    "#     'proj_clip': 5,\n",
    "#     'lr': 0.2,\n",
    "#     'shuffle': False,\n",
    "#     'n_lstm_layers': 1,\n",
    "#     'n_highway_layers': 1,\n",
    "#     'cnn_filters': [[1, 32],\n",
    "#                     [2, 32],\n",
    "#                     [3, 64],\n",
    "#                     [4, 128],\n",
    "#                     [5, 256],\n",
    "#                     [6, 512],\n",
    "#                     [7, 512]\n",
    "#                     ],\n",
    "#     'lstm_units_size': 50,\n",
    "#     'hidden_units_size': 50,\n",
    "#     'char_embedding_size': 16,\n",
    "#     'dropout_rate': 0.1,\n",
    "#     'word_dropout_rate': 0.05,\n",
    "#     'weight_tying': True,\n",
    "#     'unidirectional': True,\n",
    "#     'subwords': False,\n",
    "#      'use_multibpemd': False,\n",
    "# }\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'name': 'cm_girnet_tweeter_multiembd',\n",
    "    'multi_processing': True,\n",
    "    'n_threads': 10,\n",
    "    'cuDNN': True if len(K.tensorflow_backend._get_available_gpus()) else False,\n",
    "    'train_dataset': 'cm_p_train_small.txt',\n",
    "    'valid_dataset': 'cm_p_test_1000.txt',\n",
    "    'test_dataset': 'cm_test_main_1000.txt',\n",
    "    'vocab': 'well bleb',\n",
    "    'vocab_size': 54497,\n",
    "    'num_sampled': 8000,\n",
    "    'charset_size': 262,\n",
    "    'sentence_maxlen': 64,\n",
    "    'token_maxlen': 50,\n",
    "    'token_encoding': 'word',\n",
    "    'epochs': 1,\n",
    "    'patience': 2,\n",
    "    'batch_size': 4,\n",
    "    'clip_value': 1,\n",
    "    'cell_clip': 5,\n",
    "    'proj_clip': 5,\n",
    "    'lr': 0.2,\n",
    "    'shuffle': True,\n",
    "    'n_lstm_layers': 1,\n",
    "    'n_highway_layers': 1,\n",
    "    'cnn_filters': [[1, 32],\n",
    "                    [2, 32],\n",
    "                    [3, 64],\n",
    "                    [4, 128],\n",
    "                    [5, 256],\n",
    "                    [6, 512],\n",
    "                    [7, 512]\n",
    "                    ],\n",
    "    'lstm_units_size': 600,\n",
    "    'hidden_units_size': 200,\n",
    "    'char_embedding_size': 16,\n",
    "    'dropout_rate': 0.1,\n",
    "    'word_dropout_rate': 0.05,\n",
    "    'weight_tying': True,\n",
    "    'unidirectional': True,\n",
    "    'subwords': False,\n",
    "    'use_multibpemd': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_multibpemd = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "train_generator = MTLLMDataGenerator([os.path.join(DATA_SET_DIR, 'en_p_train_small.txt'),\n",
    "                                      os.path.join(DATA_SET_DIR, 'es_p_train_small.txt'),\n",
    "                                      os.path.join(DATA_SET_DIR, 'cm_p_train_small.txt')],\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'],\n",
    "                                     use_multibpemd=use_multibpemd\n",
    ")\n",
    "val_generator = MTLLMDataGenerator([os.path.join(DATA_SET_DIR, 'cm_p_test_100.txt'),\n",
    "                                    os.path.join(DATA_SET_DIR, 'cm_p_test_100.txt'),\n",
    "                                    os.path.join(DATA_SET_DIR, 'cm_p_test_100.txt')],\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'],\n",
    "                                   use_multibpemd=use_multibpemd\n",
    ")\n",
    "test_generator = MTLLMDataGenerator([os.path.join(DATA_SET_DIR, parameters['test_dataset']),\n",
    "                                     os.path.join(DATA_SET_DIR, parameters['test_dataset']),\n",
    "                                     os.path.join(DATA_SET_DIR, parameters['test_dataset'])],\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'],\n",
    "                                    use_multibpemd=use_multibpemd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_generator =  LMDataGenerator(os.path.join(DATA_SET_DIR, 'english.txt'),\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'],\n",
    "                                     use_multibpemd=use_multibpemd)\n",
    "\n",
    "train_es_generator =  LMDataGenerator(os.path.join(DATA_SET_DIR, 'hindi.txt'),\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'],\n",
    "                                     use_multibpemd=use_multibpemd)\n",
    "\n",
    "train_cm_generator =  LMDataGenerator(os.path.join(DATA_SET_DIR, 'cm.txt'),\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'],\n",
    "                                     use_multibpemd=use_multibpemd)\n",
    "\n",
    "test_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['test_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'],\n",
    "                                use_multibpemd=use_multibpemd)\n",
    "val_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['valid_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'],\n",
    "                               use_multibpemd=use_multibpemd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up Generators\n",
    "train_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['train_dataset']),\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'],\n",
    "                                 use_multibpemd=use_multibpemd)\n",
    "\n",
    "val_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['valid_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'],\n",
    "                               use_multibpemd=use_multibpemd)\n",
    "\n",
    "test_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['test_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'],\n",
    "                                use_multibpemd=use_multibpemd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parameters['use_multibpemd']:\n",
    "    parameters['pretrained_embed'] = train_generator.data1.multibpemd.vectors\n",
    "    parameters['vocab_size'] = train_generator.data1.multibpemd.vocab_size\n",
    "    parameters['hidden_units_size'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_impl.py:1444: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    }
   ],
   "source": [
    "# Compile ELMo\n",
    "elmo_model = ELMo(parameters)\n",
    "elmo_model.compile_elmo(print_summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "  6142/500000 [..............................] - ETA: 71:20:48 - loss: 10.3161"
     ]
    }
   ],
   "source": [
    "# for tr in [train_en_generator, train_es_generator, train_cm_generator]:\n",
    "#     elmo_model.train(train_data=tr, valid_data=val_generator)\n",
    "# 4.6\n",
    "elmo_model.train(train_data=train_generator, valid_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_model.load_temp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "elmo_model.save(sampled_softmax=False, temp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langauge Model Perplexity 2: 43688.028142\n"
     ]
    }
   ],
   "source": [
    "# cm_p_test_1000.txt\n",
    "# vanilla :  46.75967671612614\n",
    "# mtl: 39.42567465448776\n",
    "# girnet: 165.677334\n",
    "# cm_main_test_10010.txt\n",
    "# vanilla :  73.61951568054178\n",
    "# vanilla_4 : 53.722699251300426\n",
    "# mtl: 58.723475872121696\n",
    "# mtl_4:\n",
    "# girnet: 115.844843\n",
    "# girnet_4: 22.249534\n",
    "\n",
    "# vanilla_bpe: 91.73161858208685\n",
    "# vanilla_multibpemd_4: 91.60712244513829\n",
    "# vanilla_bpe_4: 53.753941728994036\n",
    "# vanilla bpe_1: 51.95905007072605\n",
    "# mlt bpe_4: 46.614687442883785\n",
    "# girnet_bpe_4: 18.187604\n",
    "\n",
    "# VCS_GIRNET_4_1: 363.432520 / no sampling: 214.172797/ 189.699757\n",
    "# mtl: 214.18284865336776, 166.37407541932322\n",
    "# vanilla_4_1: 420.294477 /no sampling: 136.28547085188885\n",
    "\n",
    "\n",
    "elmo_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = test_generator.vocab\n",
    "id2word = {}\n",
    "for key in vocab:\n",
    "    id2word[vocab[key]] = key\n",
    "def decode(sents_index):\n",
    "    ans = \"\"\n",
    "    for index in sents_index:\n",
    "        ans = ans +  id2word[index] + \" \"\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = elmo_model.generate([2,6], size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ▁d ▁кордон ameistr ▁আলো ▁generolas ▁width ксо ▁programm ▁רחבה allaş ▁منها díj ▁अवर ▁penget ▁úd ▁භා ▁λε ▁предупре azan ▁ilgis ▁տեղակայված ▁ослобо ▁lännessä ▁طوال ▁zmer ▁laimėjo ▁peper ▁свеце ▁monograph ▁óla ρωμα '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_model._model.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ELMo meta-model to deploy for production and persist in disk\n",
    "# elmo_model.wrap_multi_elmo_encoder(print_summary=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elmo_model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ELMo embeddings to feed as inputs for downstream tasks\n",
    "# elmo_embeddings = elmo_model.get_outputs(test_generator, output_type='word', state='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        def unpad(x, y_true, y_pred):\n",
    "            y_true_unpad = []\n",
    "            y_pred_unpad = []\n",
    "            for i, x_i in enumerate(x):\n",
    "                for j, x_ij in enumerate(x_i):\n",
    "                    if x_ij == 0:\n",
    "                        y_true_unpad.append(y_true[i][:j])\n",
    "                        y_pred_unpad.append(y_pred[i][:j])\n",
    "                        break\n",
    "            return np.asarray(y_true_unpad), np.asarray(y_pred_unpad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Generate samples\n",
    "        x, y_true_forward, y_true_backward = [], [], []\n",
    "        for i in range(len(test_data)):\n",
    "            test_batch = test_data[i][0]\n",
    "            x.extend(test_batch[0])\n",
    "            y_true_forward.extend(test_batch[1])\n",
    "            y_true_backward.extend(test_batch[2])\n",
    "        x = np.asarray(x)\n",
    "        y_true_forward = np.asarray(y_true_forward)\n",
    "        y_true_backward = np.asarray(y_true_backward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_forward = elmo_model._model.predict([x, y_true_forward, y_true_backward])\n",
    "# y_true_forward, y_pred_forward = unpad(x, y_true_forward, y_pred_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_forward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_forward = y_true_forward.reshape(1250,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_forward = y_true_forward.reshape(1250,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_forward = to_categorical(y_true_forward, y_pred_forward.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = K.categorical_crossentropy(\n",
    "    K.tf.convert_to_tensor(y_true_forward, dtype=K.tf.float32),\n",
    "    K.tf.convert_to_tensor(y_pred_forward,  dtype=K.tf.float32),\n",
    "    from_logits=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_x = entropy.eval(session=K.get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow(2,np.mean(np.asarray(entropy_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hote = to_categorical(y_pred_forward, y_pred_forward.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

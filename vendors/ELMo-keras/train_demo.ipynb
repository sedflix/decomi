{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras.backend as K\n",
    "\n",
    "from elmo.lm_generator import LMDataGenerator, MTLLMDataGenerator\n",
    "from elmo.model_girnet import ELMo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "- fasttext: sent_vector: unsup: [0.5040783036202435, 0.44986425566245447]\n",
    "- fasttext: sent_vector: sup: [0.5628058728541675, 0.5187983749157842]\n",
    "- fasttext: lstm: unsup [0.6182707995419401, 0.5768815131210775] \n",
    "- fasttext: lstm: sup [0.6705, 0.6624]\n",
    "- MultiBPEmb: lstm: unsup: 0.52\n",
    "- MultiBPEmb: lstm: sup: 0.64\n",
    "\n",
    "### cm_p_test_1000.txt\n",
    "- vanilla :  46.75967671612614\n",
    "- mtl: 39.42567465448776\n",
    "- girnet: 165.677334\n",
    "\n",
    "###  cm_main_test_1000.txt\n",
    "- vanilla :  73.61951568054178\n",
    "- mtl: 58.723475872121696\n",
    "- girnet: 132.512263\n",
    "\n",
    "Conclusion: SUBWORDS RULE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SET_DIR = '../twiter_scrapping/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'name': 'cm_girnet',\n",
    "    'multi_processing': True,\n",
    "    'n_threads': 10,\n",
    "    'cuDNN': True if len(K.tensorflow_backend._get_available_gpus()) else False,\n",
    "    'train_dataset': 'cm_p_train_small.txt',\n",
    "    'valid_dataset': 'cm_p_test_1000.txt',\n",
    "    'test_dataset': 'cm_test_main_1000.txt',\n",
    "    'vocab': 'vocab',\n",
    "    'vocab_size': 525133,\n",
    "    'num_sampled': 8000,\n",
    "    'charset_size': 262,\n",
    "    'sentence_maxlen': 32,\n",
    "    'token_maxlen': 50,\n",
    "    'token_encoding': 'word',\n",
    "    'epochs': 1,\n",
    "    'patience': 2,\n",
    "    'batch_size': 32,\n",
    "    'clip_value': 1,\n",
    "    'cell_clip': 5,\n",
    "    'proj_clip': 5,\n",
    "    'lr': 0.2,\n",
    "    'shuffle': True,\n",
    "    'n_lstm_layers': 1,\n",
    "    'n_highway_layers': 1,\n",
    "    'cnn_filters': [[1, 32],\n",
    "                    [2, 32],\n",
    "                    [3, 64],\n",
    "                    [4, 128],\n",
    "                    [5, 256],\n",
    "                    [6, 512],\n",
    "                    [7, 512]\n",
    "                    ],\n",
    "    'lstm_units_size': 400,\n",
    "    'hidden_units_size': 200,\n",
    "    'char_embedding_size': 16,\n",
    "    'dropout_rate': 0.1,\n",
    "    'word_dropout_rate': 0.05,\n",
    "    'weight_tying': True,\n",
    "    'unidirectional': True,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = MTLLMDataGenerator([os.path.join(DATA_SET_DIR, 'en_p_train_small.txt'),os.path.join(DATA_SET_DIR, 'es_p_train_small.txt'),os.path.join(DATA_SET_DIR, 'cm_p_train_small.txt')],\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding']\n",
    ")\n",
    "val_generator = MTLLMDataGenerator([os.path.join(DATA_SET_DIR, 'en_p_test_1000.txt'),os.path.join(DATA_SET_DIR, 'es_p_test_1000.txt'),os.path.join(DATA_SET_DIR, 'cm_p_test_1000.txt')],\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding']\n",
    ")\n",
    "test_generator = MTLLMDataGenerator([os.path.join(DATA_SET_DIR, parameters['test_dataset']),os.path.join(DATA_SET_DIR, parameters['test_dataset']),os.path.join(DATA_SET_DIR, parameters['test_dataset'])],\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_en_generator =  LMDataGenerator(os.path.join(DATA_SET_DIR, 'en_p_train_small.txt'),\n",
    "#                                   os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "#                                   sentence_maxlen=parameters['sentence_maxlen'],\n",
    "#                                   token_maxlen=parameters['token_maxlen'],\n",
    "#                                   batch_size=parameters['batch_size'],\n",
    "#                                   shuffle=parameters['shuffle'],\n",
    "#                                   token_encoding=parameters['token_encoding'])\n",
    "\n",
    "# train_es_generator =  LMDataGenerator(os.path.join(DATA_SET_DIR, 'es_p_train_small.txt'),\n",
    "#                                   os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "#                                   sentence_maxlen=parameters['sentence_maxlen'],\n",
    "#                                   token_maxlen=parameters['token_maxlen'],\n",
    "#                                   batch_size=parameters['batch_size'],\n",
    "#                                   shuffle=parameters['shuffle'],\n",
    "#                                   token_encoding=parameters['token_encoding'])\n",
    "\n",
    "# train_cm_generator =  LMDataGenerator(os.path.join(DATA_SET_DIR, 'cm_p_train_small.txt'),\n",
    "#                                   os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "#                                   sentence_maxlen=parameters['sentence_maxlen'],\n",
    "#                                   token_maxlen=parameters['token_maxlen'],\n",
    "#                                   batch_size=parameters['batch_size'],\n",
    "#                                   shuffle=parameters['shuffle'],\n",
    "#                                   token_encoding=parameters['token_encoding'])\n",
    "\n",
    "# test_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['test_dataset']),\n",
    "#                                 os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "#                                 sentence_maxlen=parameters['sentence_maxlen'],\n",
    "#                                 token_maxlen=parameters['token_maxlen'],\n",
    "#                                 batch_size=parameters['batch_size'],\n",
    "#                                 shuffle=parameters['shuffle'],\n",
    "#                                 token_encoding=parameters['token_encoding'])\n",
    "# val_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['valid_dataset']),\n",
    "#                                 os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "#                                 sentence_maxlen=parameters['sentence_maxlen'],\n",
    "#                                 token_maxlen=parameters['token_maxlen'],\n",
    "#                                 batch_size=parameters['batch_size'],\n",
    "#                                 shuffle=parameters['shuffle'],\n",
    "#                                 token_encoding=parameters['token_encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up Generators\n",
    "train_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['train_dataset']),\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'])\n",
    "\n",
    "val_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['valid_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'])\n",
    "\n",
    "test_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['test_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_impl.py:1444: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    }
   ],
   "source": [
    "# Compile ELMo\n",
    "elmo_model = ELMo(parameters)\n",
    "elmo_model.compile_elmo(print_summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 4246/62500 [=>............................] - ETA: 12:27:07 - loss: 5.6353"
     ]
    }
   ],
   "source": [
    "# for tr in [train_en_generator, train_es_generator, train_cm_generator]:\n",
    "#     elmo_model.train(train_data=tr, valid_data=val_generator)\n",
    "#  5.5218\n",
    "elmo_model.train(train_data=train_generator, valid_data=val_generator, resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_model.load_temp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "elmo_model.save(sampled_softmax=False, temp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cm_p_test_1000.txt\n",
    "# vanilla :  46.75967671612614\n",
    "# mtl: 39.42567465448776\n",
    "# girnet: 165.677334\n",
    "# cm_main_test_1000.txt\n",
    "# vanilla :  73.61951568054178\n",
    "# mtl: 58.723475872121696\n",
    "# girnet: 132.512263\n",
    "elmo_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sup\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ELMo meta-model to deploy for production and persist in disk\n",
    "# elmo_model.wrap_multi_elmo_encoder(print_summary=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elmo_model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ELMo embeddings to feed as inputs for downstream tasks\n",
    "# elmo_embeddings = elmo_model.get_outputs(test_generator, output_type='word', state='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

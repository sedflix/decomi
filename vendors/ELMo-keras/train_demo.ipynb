{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras.backend as K\n",
    "from elmo.lm_generator import LMDataGenerator, MTLLMDataGenerator\n",
    "from elmo.model_girnet import ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fastBPE\n",
    "# bpe = fastBPE.fastBPE(\"../twiter_scrapping/preprocess/fastBPE/codes\", \"../twiter_scrapping/data/vocab.en.es.40000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "- fasttext: sent_vector: unsup: [0.5040783036202435, 0.44986425566245447]\n",
    "- fasttext: sent_vector: sup: [0.5628058728541675, 0.5187983749157842]\n",
    "- fasttext: lstm: unsup [0.6182707995419401, 0.5768815131210775] \n",
    "- fasttext: lstm: sup [0.6705, 0.6624]\n",
    "- MultiBPEmb: lstm: unsup: 0.52\n",
    "- MultiBPEmb: lstm: sup: 0.64\n",
    "\n",
    "## Word Vocab\n",
    "\n",
    "### cm_p_test_1000.txt\n",
    "- vanilla :  46.75967671612614\n",
    "- mtl: 39.42567465448776\n",
    "- girnet: 165.677334\n",
    "\n",
    "###  cm_main_test_1000.txt\n",
    "- vanilla : 53.722(4), 73.619(32)\n",
    "- mtl: 58.723(32), 46.54(3)\n",
    "- girnet: 22(4), 115(64)\n",
    "\n",
    "## BPE\n",
    "###  cm_main_test_1000.txt\n",
    "- vanilla_bpe: 51.959(1), 53.7539(4), 91.7316(64)\n",
    "- mlt_bpe: 46.614(4)\n",
    "- girnet_bpe: 18.187604(4)\n",
    "\n",
    "Conclusion: S4UBWORDS RULE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_SET_DIR = '../twiter_scrapping/data/'\n",
    "DATA_SET_DIR = '../../data/Dataset_VACS/Language Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#     'name': 'cm_mtl_4',\n",
    "#     'multi_processing': True,\n",
    "#     'n_threads': 10,\n",
    "#     'cuDNN': True if len(K.tensorflow_backend._get_available_gpus()) else False,\n",
    "#     'train_dataset': 'cm_p_train_small.txt',\n",
    "#     'valid_dataset': 'cm_p_test_1000.txt',\n",
    "#     'test_dataset': 'cm_test_main_1000.txt',\n",
    "#     'vocab': 'vocab',\n",
    "#     'vocab_size': 525133,\n",
    "#     'num_sampled': 8000,\n",
    "#     'charset_size': 262,\n",
    "#     'sentence_maxlen': 32,\n",
    "#     'token_maxlen': 50,\n",
    "#     'token_encoding': 'word',\n",
    "#     'epochs': 1,\n",
    "#     'patience': 2,\n",
    "#     'batch_size': 4,\n",
    "#     'clip_value': 1,\n",
    "#     'cell_clip': 5,\n",
    "#     'proj_clip': 5,\n",
    "#     'lr': 0.2,\n",
    "#     'shuffle': True,\n",
    "#     'n_lstm_layers': 1,\n",
    "#     'n_highway_layers': 1,\n",
    "#     'cnn_filters': [[1, 32],\n",
    "#                     [2, 32],\n",
    "#                     [3, 64],\n",
    "#                     [4, 128],\n",
    "#                     [5, 256],\n",
    "#                     [6, 512],\n",
    "#                     [7, 512]\n",
    "#                     ],\n",
    "#     'lstm_units_size': 400,\n",
    "#     'hidden_units_size': 200,\n",
    "#     'char_embedding_size': 16,\n",
    "#     'dropout_rate': 0.1,\n",
    "#     'word_dropout_rate': 0.05,\n",
    "#     'weight_tying': True,\n",
    "#     'unidirectional': True,\n",
    "#     'subwords': False,\n",
    "# }\n",
    "\n",
    "# parameters = {\n",
    "#     'name': 'cm_mtl_bpe_4',\n",
    "#     'multi_processing': True,\n",
    "#     'n_threads': 10,\n",
    "#     'cuDNN': True if len(K.tensorflow_backend._get_available_gpus()) else False,\n",
    "#     'train_dataset': 'cm_p_train_small.txt.40000',\n",
    "#     'valid_dataset': 'cm_p_test_1000.txt.40000',\n",
    "#     'test_dataset': 'cm_test_main_1000.txt.40000',\n",
    "#     'vocab': 'vocab.en.es.40000.processed',\n",
    "#     'vocab_size': 54497,\n",
    "#     'num_sampled': 2000,\n",
    "#     'charset_size': 262,\n",
    "#     'sentence_maxlen': 32,\n",
    "#     'token_maxlen': 50,\n",
    "#     'token_encoding': 'word',\n",
    "#     'epochs': 1,\n",
    "#     'patience': 2,\n",
    "#     'batch_size': 4,\n",
    "#     'clip_value': 1,\n",
    "#     'cell_clip': 5,\n",
    "#     'proj_clip': 5,\n",
    "#     'lr': 0.2,\n",
    "#     'shuffle': True,\n",
    "#     'n_lstm_layers': 1,\n",
    "#     'n_highway_layers': 1,\n",
    "#     'cnn_filters': [[1, 32],\n",
    "#                     [2, 32],\n",
    "#                     [3, 64],\n",
    "#                     [4, 128],\n",
    "#                     [5, 256],\n",
    "#                     [6, 512],\n",
    "#                     [7, 512]\n",
    "#                     ],\n",
    "#     'lstm_units_size': 400,\n",
    "#     'hidden_units_size': 200,\n",
    "#     'char_embedding_size': 16,\n",
    "#     'dropout_rate': 0.1,\n",
    "#     'word_dropout_rate': 0.05,\n",
    "#     'weight_tying': True,\n",
    "#     'unidirectional': True,\n",
    "#     'subwords': False\n",
    "# }\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'name': 'cm_girnet_vcs_data',\n",
    "    'multi_processing': True,\n",
    "    'n_threads': 10,\n",
    "    'cuDNN': True if len(K.tensorflow_backend._get_available_gpus()) else False,\n",
    "    'train_dataset': 'cm_p_train_small.txt',\n",
    "    'valid_dataset': 'valid.txt',\n",
    "    'test_dataset': 'test.txt',\n",
    "    'vocab': 'fvocab',\n",
    "    'vocab_size': 12688,\n",
    "    'num_sampled': 2000,\n",
    "    'charset_size': 262,\n",
    "    'sentence_maxlen': 32,\n",
    "    'token_maxlen': 50,\n",
    "    'token_encoding': 'word',\n",
    "    'epochs': 1,\n",
    "    'patience': 2,\n",
    "    'batch_size': 4,\n",
    "    'clip_value': 1,\n",
    "    'cell_clip': 5,\n",
    "    'proj_clip': 5,\n",
    "    'lr': 0.2,\n",
    "    'shuffle': False,\n",
    "    'n_lstm_layers': 1,\n",
    "    'n_highway_layers': 1,\n",
    "    'cnn_filters': [[1, 32],\n",
    "                    [2, 32],\n",
    "                    [3, 64],\n",
    "                    [4, 128],\n",
    "                    [5, 256],\n",
    "                    [6, 512],\n",
    "                    [7, 512]\n",
    "                    ],\n",
    "    'lstm_units_size': 200,\n",
    "    'hidden_units_size': 100,\n",
    "    'char_embedding_size': 16,\n",
    "    'dropout_rate': 0.1,\n",
    "    'word_dropout_rate': 0.05,\n",
    "    'weight_tying': True,\n",
    "    'unidirectional': True,\n",
    "    'subwords': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = MTLLMDataGenerator([os.path.join(DATA_SET_DIR, 'english.txt'),\n",
    "                                      os.path.join(DATA_SET_DIR, 'hindi.txt'),\n",
    "                                      os.path.join(DATA_SET_DIR, 'cm.txt')],\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding']\n",
    ")\n",
    "val_generator = MTLLMDataGenerator([os.path.join(DATA_SET_DIR, 'valid.txt'),\n",
    "                                    os.path.join(DATA_SET_DIR, 'valid.txt'),\n",
    "                                    os.path.join(DATA_SET_DIR, 'valid.txt')],\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding']\n",
    ")\n",
    "test_generator = MTLLMDataGenerator([os.path.join(DATA_SET_DIR, parameters['test_dataset']),os.path.join(DATA_SET_DIR, parameters['test_dataset']),os.path.join(DATA_SET_DIR, parameters['test_dataset'])],\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_generator =  LMDataGenerator(os.path.join(DATA_SET_DIR, 'en_p_train_small.txt'),\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'])\n",
    "\n",
    "train_es_generator =  LMDataGenerator(os.path.join(DATA_SET_DIR, 'es_p_train_small.txt'),\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'])\n",
    "\n",
    "train_cm_generator =  LMDataGenerator(os.path.join(DATA_SET_DIR, 'cm_p_train_small.txt'),\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'])\n",
    "\n",
    "test_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['test_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'])\n",
    "val_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['valid_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up Generators\n",
    "train_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['train_dataset']),\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'])\n",
    "\n",
    "val_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['valid_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'])\n",
    "\n",
    "test_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['test_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile ELMo\n",
    "elmo_model = ELMo(parameters)\n",
    "elmo_model.compile_elmo(print_summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "313/313 [==============================] - 119s 379ms/step - loss: 3.1002 - val_loss: 6.5039\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.50392, saving model to /app/vendors/ELMo-keras/data/models/elmo_best_weights.hdf5\n",
      "Training took 118.8310923576355 sec\n"
     ]
    }
   ],
   "source": [
    "# for tr in [train_en_generator, train_es_generator, train_cm_generator]:\n",
    "#     elmo_model.train(train_data=tr, valid_data=val_generator)\n",
    "# 4.6\n",
    "elmo_model.train(train_data=train_generator, valid_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_model.load_temp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /app/vendors/ELMo-keras/elmo/custom_layers/sampled_softmax.py:55: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Language Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "elmo_model.save(sampled_softmax=False, temp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"trained\" > status.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langauge Model Perplexity 1: 752.939329\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1d1b9340d088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# girnet_bpe_4: 18.187604\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0melmo_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/app/vendors/ELMo-keras/elmo/model_girnet.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, test_data)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Langauge Model Perplexity %d: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mELMo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap_multi_elmo_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_summary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/vendors/ELMo-keras/elmo/model_girnet.py\u001b[0m in \u001b[0;36mperplexity\u001b[0;34m(y_pred, y_true)\u001b[0m\n\u001b[1;32m    406\u001b[0m             cross_entropy = K.categorical_crossentropy(K.tf.convert_to_tensor(y_true_seq, dtype=K.tf.float32),\n\u001b[1;32m    407\u001b[0m                                                        K.tf.convert_to_tensor(y_pred_seq, dtype=K.tf.float32))\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0mcross_entropies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;31m# Compute mean cross_entropy and perplexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5179\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5180\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5181\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cm_p_test_1000.txt\n",
    "# vanilla :  46.75967671612614\n",
    "# mtl: 39.42567465448776\n",
    "# girnet: 165.677334\n",
    "# cm_main_test_10010.txt\n",
    "# vanilla :  73.61951568054178\n",
    "# vanilla_4 : 53.722699251300426\n",
    "# mtl: 58.723475872121696\n",
    "# mtl_4:\n",
    "# girnet: 115.844843\n",
    "# girnet_4: 22.249534\n",
    "\n",
    "# vanilla_bpe: 91.73161858208685\n",
    "# vanilla_bpe_4: 53.753941728994036\n",
    "# vanilla bpe_1: 51.95905007072605\n",
    "# mlt bpe_4: 46.614687442883785\n",
    "# girnet_bpe_4: 18.187604\n",
    "\n",
    "elmo_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_model._model.evaluate_generator(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ELMo meta-model to deploy for production and persist in disk\n",
    "# elmo_model.wrap_multi_elmo_encoder(print_summary=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elmo_model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ELMo embeddings to feed as inputs for downstream tasks\n",
    "# elmo_embeddings = elmo_model.get_outputs(test_generator, output_type='word', state='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

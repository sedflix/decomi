{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python35.zip',\n",
       " '/usr/lib/python3.5',\n",
       " '/usr/lib/python3.5/plat-x86_64-linux-gnu',\n",
       " '/usr/lib/python3.5/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.5/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.5/dist-packages/IPython/extensions',\n",
       " '/root/.ipython']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include useful folders\n",
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install dlblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../vendors/mtl_girnet/data_prep/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from twtokenize import tokenize\n",
    "# from keras.utils import to_categorical\n",
    "# from xml.dom import minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokensize_deepmoji import tokenize\n",
    "from xml.dom import minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = {\"N\":-1 , \"P\" :1 , \"NONE\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"../vendors/mtl_girnet/data_prep/data_cm_senti/cs-corpus-with-tweets_train.txt\", encoding='utf-8').read().split(\"\\n\") \n",
    "data = map( lambda x : x.split(\"\\t\") , data )\n",
    "data = map( lambda x :{'sentiment': sents[x[1]] , 'tokens': tokenize(x[2]) , 'text': x[2] } , data )\n",
    "en_es_wssa_data_train = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"../vendors/mtl_girnet/data_prep/data_cm_senti/cs-corpus-with-tweets_test.txt\", encoding='utf-8').read().split(\"\\n\") \n",
    "data = map( lambda x : x.split(\"\\t\") , data )\n",
    "data = map( lambda x :{'sentiment': sents[x[1]] , 'tokens': tokenize(x[2]) , 'text': x[2] } , data )\n",
    "en_es_wssa_data_test = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_es_wssa_data = list(en_es_wssa_data_train) + list(en_es_wssa_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmldoc = minidom.parse(\"../vendors/mtl_girnet/data_prep/data_cm_senti/general-tweets-train-tagged.xml\")\n",
    "tweets = xmldoc.getElementsByTagName('tweet')\n",
    "\n",
    "sents = {\"N\":-1 , \"P\" :1 , \"NEU\":0 , 'NONE':0 , \"P+\" : 1 , \"N+\":-1 }\n",
    "\n",
    "\n",
    "es_tass1_data = []\n",
    "\n",
    "for i in range( len(tweets)-1) :\n",
    "    if i == 6055:\n",
    "        continue # bad jogar\n",
    "    textt = tweets[i].getElementsByTagName('content')[0].childNodes[0].data\n",
    "    words = tokenize( textt )\n",
    "    sentiment = tweets[i].getElementsByTagName('polarity')[0].getElementsByTagName('value')[0].childNodes[0].data\n",
    "    assert len(tweets[i].getElementsByTagName('polarity')[0].getElementsByTagName('entity'))==0\n",
    "    es_tass1_data.append({'text':textt , 'tokens':words , 'sentiment': sents[sentiment] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"../vendors/mtl_girnet/data_prep/data_cm_senti/twitter4242.txt\", \"r\", encoding=\"utf-8\",errors='ignore').read().split(\"\\n\")[1:-1]\n",
    "data = map( lambda x : x.split(\"\\t\") , data )\n",
    "data = map( lambda x :{'sentiment': int(np.sign(int(x[0])-int(x[1]))) , 'tokens': tokenize(x[2]) , 'text': x[2] } , data )\n",
    "\n",
    "en_twitter_data = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"../vendors/mtl_girnet/data_prep/data_cm_senti/1600_tweets_dev_complete.txt\", encoding=\"utf-8\").read().split(\"\\n\")[1:-1]\n",
    "data += open(\"../vendors/mtl_girnet/data_prep/data_cm_senti/1600_tweets_test_average_complete.tsv\", encoding=\"utf-8\").read().split(\"\\n\")[1:-2]\n",
    "\n",
    "data = map( lambda x : x.split(\"\\t\") , data )\n",
    "data = map( lambda x :{'sentiment': int(np.sign(int(x[0])-int(x[1]))) , 'tokens': tokenize(x[2]) , 'text': x[2] } , data )\n",
    "\n",
    "es2_twitter_data = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4241\n",
      "3202\n",
      "3062\n"
     ]
    }
   ],
   "source": [
    "print(len(en_twitter_data))\n",
    "print(len(es2_twitter_data))\n",
    "print(len(en_es_wssa_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vec(emb_path, nmax=50000):\n",
    "    vectors = []\n",
    "    word2id = {}\n",
    "    with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "        next(f)\n",
    "        for i, line in enumerate(f):\n",
    "            word, vect = line.rstrip().split(' ', 1)\n",
    "            vect = np.fromstring(vect, sep=' ')\n",
    "            assert word not in word2id, 'word found twice'\n",
    "            vectors.append(vect)\n",
    "            word2id[word] = len(word2id)\n",
    "            if len(word2id) == nmax:\n",
    "                break\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    embeddings = np.vstack(vectors)\n",
    "    return embeddings, id2word, word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = '../vendors//MUSE/dumped/debug/4u9hakomha/vectors-en.txt'\n",
    "tgt_path = '../vendors//MUSE/dumped/debug/4u9hakomha/vectors-es.txt'\n",
    "nmax = 100000  # maximum number of word embeddings to load\n",
    "\n",
    "src_embeddings, src_id2word, src_word2id = load_vec(src_path, nmax)\n",
    "tgt_embeddings, tgt_id2word, tgt_word2id = load_vec(tgt_path, nmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn(word, src_emb, src_id2word, tgt_emb, tgt_id2word, K=5):\n",
    "    print(\"Nearest neighbors of \\\"%s\\\":\" % word)\n",
    "    word2id = {v: k for k, v in src_id2word.items()}\n",
    "    word_emb = src_emb[word2id[word]]\n",
    "    scores = (tgt_emb / np.linalg.norm(tgt_emb, 2, 1)[:, None]).dot(word_emb / np.linalg.norm(word_emb))\n",
    "    k_best = scores.argsort()[-K:][::-1]\n",
    "    for i, idx in enumerate(k_best):\n",
    "        print('%.4f - %s' % (scores[idx], tgt_id2word[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors of \"cat\":\n",
      "1.0000 - cat\n",
      "0.7322 - cats\n",
      "0.6453 - kitten\n",
      "0.6381 - dog\n",
      "0.6218 - kittens\n"
     ]
    }
   ],
   "source": [
    "# printing nearest neighbors in the source space\n",
    "src_word = 'cat'\n",
    "get_nn(src_word, src_embeddings, src_id2word, src_embeddings, src_id2word, K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors of \"cat\":\n",
      "0.6266 - gato\n",
      "0.5317 - perro\n",
      "0.5213 - gatito\n",
      "0.4872 - gorila\n",
      "0.4767 - ratoncito\n"
     ]
    }
   ],
   "source": [
    "# printing nearest neighbors in the target space\n",
    "src_word = 'cat'\n",
    "get_nn(src_word, src_embeddings, src_id2word, tgt_embeddings, tgt_id2word, K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 300)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Preprocessing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = src_embeddings.copy().tolist()\n",
    "embedding_matrix.extend(tgt_embeddings.tolist())\n",
    "embedding_matrix = np.array(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = src_id2word.copy()\n",
    "word2id = src_word2id.copy()\n",
    "next_id = len(id2word.keys())\n",
    "counter = len(id2word.keys())\n",
    "to_be_removed = []\n",
    "for key in tgt_id2word:\n",
    "    if tgt_id2word[key] in word2id:\n",
    "        to_be_removed.append(counter)\n",
    "        embedding_matrix[word2id[tgt_id2word[key]]] =  (embedding_matrix[word2id[tgt_id2word[key]]] + embedding_matrix[counter])/2\n",
    "    else:\n",
    "        id2word[next_id] = tgt_id2word[key]\n",
    "        word2id[tgt_id2word[key]] = next_id\n",
    "        next_id += 1\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.delete(embedding_matrix, to_be_removed, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161832, 300)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_x(sample):\n",
    "    x = []\n",
    "    for word in sample['tokens']:\n",
    "        word = word.lower()\n",
    "        if word in word2id:\n",
    "            x.append(word2id[word])\n",
    "#         else:\n",
    "#             print(word)\n",
    "    return x\n",
    "\n",
    "def to_x_y(data_):\n",
    "    x=  list(map(lambda x : to_x(x), data_))\n",
    "    y = list(map(lambda x: x['sentiment'],data_))\n",
    "    x = list(sequence.pad_sequences(x, maxlen=MAX_SEQUENCE_LENGTH))\n",
    "    y = list(to_categorical(y,num_classes=3))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train =  to_x_y(en_twitter_data)\n",
    "temp_1, temp_2 = to_x_y(es2_twitter_data)\n",
    "x_train.extend(temp_1)\n",
    "y_train.extend(temp_2)\n",
    "temp_1, temp_2 = to_x_y(es_tass1_data)\n",
    "x_train.extend(temp_1)\n",
    "y_train.extend(temp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14660, 10)\n",
      "(14660, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9227089627391742, 1: 0.9202762084118016, 2: 1.2053938496957737}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_weight(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3062, 10)\n",
      "(3062, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = to_x_y(en_es_wssa_data)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7773546585427773, 1: 1.0598823122187608, 2: 1.2985581000848176}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_weight(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding\n",
    "EMBEDDING_DIM = embedding_matrix.shape[1] \n",
    "MAX_NUM_WORDS = embedding_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "lstm_output_size = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NUM_WORDS,\n",
    "                     EMBEDDING_DIM,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=MAX_SEQUENCE_LENGTH,\n",
    "                     trainable=False))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=pool_size))\n",
    "model.add(LSTM(lstm_output_size))\n",
    "# model.add(LSTM(128, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 10, 300)           48549600  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 6, 64)             96064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 70)                37800     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 213       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 48,683,677\n",
      "Trainable params: 134,077\n",
      "Non-trainable params: 48,549,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14660 samples, validate on 3062 samples\n",
      "Epoch 1/40\n",
      "14660/14660 [==============================] - 6s 377us/step - loss: 1.0435 - acc: 0.4521 - f1: 0.1939 - val_loss: 1.0887 - val_acc: 0.3988 - val_f1: 0.2313\n",
      "Epoch 2/40\n",
      "14660/14660 [==============================] - 3s 182us/step - loss: 0.9868 - acc: 0.5020 - f1: 0.3819 - val_loss: 1.0557 - val_acc: 0.4288 - val_f1: 0.2204\n",
      "Epoch 3/40\n",
      "14660/14660 [==============================] - 3s 212us/step - loss: 0.9555 - acc: 0.5369 - f1: 0.4309 - val_loss: 1.0692 - val_acc: 0.4046 - val_f1: 0.2489\n",
      "Epoch 4/40\n",
      "14660/14660 [==============================] - 3s 186us/step - loss: 0.9345 - acc: 0.5473 - f1: 0.4532 - val_loss: 1.0557 - val_acc: 0.4393 - val_f1: 0.2730\n",
      "Epoch 5/40\n",
      "14660/14660 [==============================] - 3s 210us/step - loss: 0.9016 - acc: 0.5761 - f1: 0.4969 - val_loss: 1.0612 - val_acc: 0.4370 - val_f1: 0.3129\n",
      "Epoch 6/40\n",
      "14660/14660 [==============================] - 3s 182us/step - loss: 0.8701 - acc: 0.5898 - f1: 0.5417 - val_loss: 1.0774 - val_acc: 0.4177 - val_f1: 0.2660\n",
      "Epoch 7/40\n",
      "14660/14660 [==============================] - 3s 178us/step - loss: 0.8411 - acc: 0.6138 - f1: 0.5657 - val_loss: 1.0943 - val_acc: 0.4170 - val_f1: 0.2824\n",
      "Epoch 8/40\n",
      "14660/14660 [==============================] - 3s 171us/step - loss: 0.8241 - acc: 0.6235 - f1: 0.5821 - val_loss: 1.1076 - val_acc: 0.4200 - val_f1: 0.2984\n",
      "Epoch 9/40\n",
      "14660/14660 [==============================] - 3s 209us/step - loss: 0.7920 - acc: 0.6413 - f1: 0.6107 - val_loss: 1.0919 - val_acc: 0.4282 - val_f1: 0.3093\n",
      "Epoch 10/40\n",
      "14660/14660 [==============================] - 3s 185us/step - loss: 0.7578 - acc: 0.6600 - f1: 0.6316 - val_loss: 1.1098 - val_acc: 0.4203 - val_f1: 0.3258\n",
      "Epoch 11/40\n",
      "14660/14660 [==============================] - 3s 201us/step - loss: 0.7444 - acc: 0.6683 - f1: 0.6426 - val_loss: 1.1156 - val_acc: 0.4105 - val_f1: 0.2851\n",
      "Epoch 12/40\n",
      "14660/14660 [==============================] - 3s 204us/step - loss: 0.7169 - acc: 0.6858 - f1: 0.6645 - val_loss: 1.1266 - val_acc: 0.4259 - val_f1: 0.3340\n",
      "Epoch 13/40\n",
      "14660/14660 [==============================] - 3s 210us/step - loss: 0.6990 - acc: 0.6925 - f1: 0.6741 - val_loss: 1.1474 - val_acc: 0.4203 - val_f1: 0.3394\n",
      "Epoch 14/40\n",
      "14660/14660 [==============================] - 3s 194us/step - loss: 0.6779 - acc: 0.7029 - f1: 0.6876 - val_loss: 1.1645 - val_acc: 0.4223 - val_f1: 0.3409\n",
      "Epoch 15/40\n",
      "14660/14660 [==============================] - 3s 190us/step - loss: 0.6697 - acc: 0.7097 - f1: 0.6914 - val_loss: 1.1611 - val_acc: 0.4255 - val_f1: 0.3731\n",
      "Epoch 16/40\n",
      "14660/14660 [==============================] - 3s 198us/step - loss: 0.6537 - acc: 0.7135 - f1: 0.6990 - val_loss: 1.1858 - val_acc: 0.4197 - val_f1: 0.3458\n",
      "Epoch 17/40\n",
      "14660/14660 [==============================] - 3s 178us/step - loss: 0.6356 - acc: 0.7253 - f1: 0.7125 - val_loss: 1.1859 - val_acc: 0.4066 - val_f1: 0.3476\n",
      "Epoch 18/40\n",
      "14660/14660 [==============================] - 3s 191us/step - loss: 0.6274 - acc: 0.7294 - f1: 0.7192 - val_loss: 1.2010 - val_acc: 0.4086 - val_f1: 0.3530\n",
      "Epoch 19/40\n",
      "14660/14660 [==============================] - 3s 174us/step - loss: 0.6081 - acc: 0.7366 - f1: 0.7267 - val_loss: 1.2491 - val_acc: 0.4053 - val_f1: 0.3548\n",
      "Epoch 20/40\n",
      "14660/14660 [==============================] - 3s 191us/step - loss: 0.6061 - acc: 0.7387 - f1: 0.7313 - val_loss: 1.2622 - val_acc: 0.4059 - val_f1: 0.3401\n",
      "Epoch 21/40\n",
      "14660/14660 [==============================] - 2s 154us/step - loss: 0.5865 - acc: 0.7523 - f1: 0.7441 - val_loss: 1.2423 - val_acc: 0.3994 - val_f1: 0.3340\n",
      "Epoch 22/40\n",
      "14660/14660 [==============================] - 3s 176us/step - loss: 0.5807 - acc: 0.7518 - f1: 0.7469 - val_loss: 1.3005 - val_acc: 0.4020 - val_f1: 0.3569\n",
      "Epoch 23/40\n",
      "14660/14660 [==============================] - 3s 176us/step - loss: 0.5802 - acc: 0.7564 - f1: 0.7484 - val_loss: 1.2309 - val_acc: 0.4170 - val_f1: 0.3712\n",
      "Epoch 24/40\n",
      "14660/14660 [==============================] - 2s 164us/step - loss: 0.5632 - acc: 0.7594 - f1: 0.7519 - val_loss: 1.2758 - val_acc: 0.4076 - val_f1: 0.3667\n",
      "Epoch 25/40\n",
      "14660/14660 [==============================] - 3s 178us/step - loss: 0.5652 - acc: 0.7649 - f1: 0.7566 - val_loss: 1.2597 - val_acc: 0.3981 - val_f1: 0.3507\n",
      "Epoch 26/40\n",
      "14660/14660 [==============================] - 3s 187us/step - loss: 0.5482 - acc: 0.7704 - f1: 0.7644 - val_loss: 1.2850 - val_acc: 0.3981 - val_f1: 0.3625\n",
      "Epoch 27/40\n",
      "14660/14660 [==============================] - 3s 190us/step - loss: 0.5506 - acc: 0.7721 - f1: 0.7661 - val_loss: 1.2552 - val_acc: 0.4099 - val_f1: 0.3694\n",
      "Epoch 28/40\n",
      "14660/14660 [==============================] - 3s 190us/step - loss: 0.5342 - acc: 0.7718 - f1: 0.7679 - val_loss: 1.3203 - val_acc: 0.3984 - val_f1: 0.3617\n",
      "Epoch 29/40\n",
      "14660/14660 [==============================] - 3s 174us/step - loss: 0.5411 - acc: 0.7752 - f1: 0.7708 - val_loss: 1.2881 - val_acc: 0.3981 - val_f1: 0.3520\n",
      "Epoch 30/40\n",
      "14660/14660 [==============================] - 3s 182us/step - loss: 0.5335 - acc: 0.7752 - f1: 0.7688 - val_loss: 1.2871 - val_acc: 0.4233 - val_f1: 0.3770\n",
      "Epoch 31/40\n",
      "14660/14660 [==============================] - 3s 186us/step - loss: 0.5315 - acc: 0.7770 - f1: 0.7723 - val_loss: 1.3330 - val_acc: 0.4089 - val_f1: 0.3666\n",
      "Epoch 32/40\n",
      "14660/14660 [==============================] - 3s 198us/step - loss: 0.5168 - acc: 0.7843 - f1: 0.7800 - val_loss: 1.3744 - val_acc: 0.3975 - val_f1: 0.3611\n",
      "Epoch 33/40\n",
      "14660/14660 [==============================] - 2s 165us/step - loss: 0.5090 - acc: 0.7857 - f1: 0.7818 - val_loss: 1.3625 - val_acc: 0.4331 - val_f1: 0.4088\n",
      "Epoch 34/40\n",
      "14660/14660 [==============================] - 3s 172us/step - loss: 0.5079 - acc: 0.7894 - f1: 0.7867 - val_loss: 1.3665 - val_acc: 0.4121 - val_f1: 0.3729\n",
      "Epoch 35/40\n",
      "14660/14660 [==============================] - 3s 174us/step - loss: 0.5116 - acc: 0.7865 - f1: 0.7816 - val_loss: 1.3460 - val_acc: 0.4170 - val_f1: 0.3871\n",
      "Epoch 36/40\n",
      "14660/14660 [==============================] - 3s 201us/step - loss: 0.4991 - acc: 0.7928 - f1: 0.7889 - val_loss: 1.4210 - val_acc: 0.3935 - val_f1: 0.3579\n",
      "Epoch 37/40\n",
      "14660/14660 [==============================] - 3s 180us/step - loss: 0.5078 - acc: 0.7873 - f1: 0.7828 - val_loss: 1.3643 - val_acc: 0.4128 - val_f1: 0.3809\n",
      "Epoch 38/40\n",
      "14660/14660 [==============================] - 3s 183us/step - loss: 0.4976 - acc: 0.7902 - f1: 0.7877 - val_loss: 1.4018 - val_acc: 0.4053 - val_f1: 0.3703\n",
      "Epoch 39/40\n",
      "14660/14660 [==============================] - 3s 193us/step - loss: 0.4905 - acc: 0.7957 - f1: 0.7914 - val_loss: 1.3852 - val_acc: 0.4157 - val_f1: 0.3961\n",
      "Epoch 40/40\n",
      "14660/14660 [==============================] - 3s 221us/step - loss: 0.4864 - acc: 0.7950 - f1: 0.7928 - val_loss: 1.3471 - val_acc: 0.4282 - val_f1: 0.3963\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=40, batch_size=64, validation_data=(x_test,y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "def get_class_weight(y):\n",
    "    \"\"\"\n",
    "    Used from: https://stackoverflow.com/a/50695814\n",
    "    TODO: check validity and 'balanced' option\n",
    "    :param y: A list of one-hot-encoding labels [[0,0,1,0],[0,0,0,1],..]\n",
    "    :return: class-weights to be used by keras model.fit(.. class_weight=\"\") -> {0:0.52134, 1:1.adas..}\n",
    "    \"\"\"\n",
    "    y_integers = np.argmax(y, axis=1)\n",
    "    class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "    return d_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlblocks import text\n",
    "from dlblocks.pyutils import mapArrays , loadJson , saveJson , selectKeys , oneHotVec , padList\n",
    "from dlblocks.pyutils import int64Arr , floatArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = text.Vocabulary()\n",
    "\n",
    "for d in es_tass1_data + en_es_wssa_data + en_twitter_data + es2_twitter_data :\n",
    "    vocab.add_words( d['tokens']  )\n",
    "\n",
    "    \n",
    "vocab.keepTopK(25000)\n",
    "\n",
    "\n",
    "\n",
    "maxSentenceL = 150\n",
    "\n",
    "def vecc( d ):\n",
    "    ret = {}\n",
    "    words   = d['tokens']\n",
    "    wordids = map( vocab , words )\n",
    "    ret['sentence'] = int64Arr( padList( wordids , maxSentenceL , 0 , 'left') )\n",
    "    ret['sentiment_val'] =  floatArr( d['sentiment'] )\n",
    "    ret['sentiment_id'] =  int64Arr( d['sentiment'] + 1 )\n",
    "    ret['sentiment_onehot'] =  floatArr( oneHotVec( d['sentiment']+1 , 3  ) )\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "en_es_wssa_data_train_arr = mapArrays( en_es_wssa_data_train , vecc )\n",
    "en_es_wssa_data_test_arr = mapArrays( en_es_wssa_data_test , vecc )\n",
    "\n",
    "en_twitter_data_train_arr = mapArrays( en_twitter_data , vecc )\n",
    "es_tass1_datatrain_arr = mapArrays( es_tass1_data , vecc )\n",
    "\n",
    "datasets = {\"en_es_wssa_data_train_arr\":en_es_wssa_data_train_arr ,\n",
    "           \"en_es_wssa_data_test_arr\":en_es_wssa_data_test_arr ,\n",
    "           \"en_twitter_data_train_arr\":en_twitter_data_train_arr ,\n",
    "           \"es_tass1_datatrain_arr\": es_tass1_datatrain_arr }\n",
    "\n",
    "\n",
    "\n",
    "outFNN = \"../data/senti_prepped.h5\"\n",
    "\n",
    "f = h5py.File(outFNN , \"w\")\n",
    "for kk in datasets.keys():\n",
    "    f.create_group( kk  )\n",
    "    for k in datasets[kk].keys():\n",
    "        f[ kk ].create_dataset( k , data=datasets[kk][k] )\n",
    "\n",
    "print \"HDF5 file created !\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
